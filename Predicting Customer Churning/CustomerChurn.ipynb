{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>REGION</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>FREQUENCE_RECH</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>ARPU_SEGMENT</th>\n",
       "      <th>FREQUENCE</th>\n",
       "      <th>DATA_VOLUME</th>\n",
       "      <th>ON_NET</th>\n",
       "      <th>ORANGE</th>\n",
       "      <th>TIGO</th>\n",
       "      <th>ZONE1</th>\n",
       "      <th>ZONE2</th>\n",
       "      <th>MRG</th>\n",
       "      <th>REGULARITY</th>\n",
       "      <th>TOP_PACK</th>\n",
       "      <th>FREQ_TOP_PACK</th>\n",
       "      <th>CHURN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dcf68cc2fb515ccad7d8b9b3bd80ee2a4b270063</td>\n",
       "      <td>SAINT-LOUIS</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>62</td>\n",
       "      <td>All-net 500F=2000F;5d</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71c44b5ba328db5c4192a80f7cf8f244d9350ed0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4427.0</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>40</td>\n",
       "      <td>Data: 100 F=40MB,24H</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce46411b1526c94f20a383b8cb188f8d27f82a0a</td>\n",
       "      <td>TAMBACOUNDA</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>32</td>\n",
       "      <td>All-net 500F=2000F;5d</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id       REGION        TENURE  \\\n",
       "0  dcf68cc2fb515ccad7d8b9b3bd80ee2a4b270063  SAINT-LOUIS  K > 24 month   \n",
       "1  71c44b5ba328db5c4192a80f7cf8f244d9350ed0          NaN  K > 24 month   \n",
       "2  ce46411b1526c94f20a383b8cb188f8d27f82a0a  TAMBACOUNDA  K > 24 month   \n",
       "\n",
       "   MONTANT  FREQUENCE_RECH  REVENUE  ARPU_SEGMENT  FREQUENCE  DATA_VOLUME  \\\n",
       "0  17000.0            32.0  18000.0        6000.0       34.0          NaN   \n",
       "1   4300.0            29.0   4427.0        1476.0       37.0       1764.0   \n",
       "2   1500.0             3.0   1500.0         500.0        3.0          NaN   \n",
       "\n",
       "   ON_NET  ORANGE  TIGO  ZONE1  ZONE2 MRG  REGULARITY               TOP_PACK  \\\n",
       "0    97.0   355.0   6.0    NaN    NaN  NO          62  All-net 500F=2000F;5d   \n",
       "1     8.0     3.0   0.0    NaN    2.0  NO          40   Data: 100 F=40MB,24H   \n",
       "2    30.0    30.0   NaN    NaN    NaN  NO          32  All-net 500F=2000F;5d   \n",
       "\n",
       "   FREQ_TOP_PACK  CHURN  \n",
       "0           35.0      0  \n",
       "1           22.0      0  \n",
       "2            3.0      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Train.csv')\n",
    "test_data = pd.read_csv('Test.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot\n",
    "print(data['CHURN'].value_counts())\n",
    "sizes = data['CHURN'].value_counts(sort = True)\n",
    "colors = [\"grey\",\"purple\"] \n",
    "rcParams['figure.figsize'] = 5,5\n",
    "labels = ['No','Yes']\n",
    "# Plot\n",
    "plt.pie(sizes, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=270,)\n",
    "plt.title('Percentage of Churn in Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the churn count for MRG\n",
    "sns.countplot(x='MRG', hue='CHURN',data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the churn count for TOP_PACK\n",
    "sns.countplot(x='TOP_PACK', hue='CHURN',data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the churn count for TENURE\n",
    "sns.countplot(x='TENURE', hue='CHURN',data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['REGION'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_country_list = test_data['REGION'].unique()\n",
    "# test_data_pack_list = test_data['TOP_PACK'].unique()\n",
    "\n",
    "## work for training data\n",
    "# data['user_id_num'] = [float(x) for x in range(len(data))]\n",
    "# X_copy = pd.DataFrame.copy(data)\n",
    "# data = data.drop(labels = ['user_id','TENURE','REGION','TOP_PACK','MRG'],axis=1)\n",
    "data = data.drop(labels = ['user_id','MRG','TOP_PACK'],axis=1)\n",
    "# data['REGION'] = data['REGION'].apply(lambda x: x if x in test_data_country_list else 'DAKAR')\n",
    "# data = data[~data.REGION.str.contains('MISSING')]\n",
    "# data['TOP_PACK'] = data['TOP_PACK'].apply(lambda x: x if x in test_data_pack_list else 'MISSING')\n",
    "# data = data[~data.TOP_PACK.str.contains('MISSING')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(data['REGION'].unique()))\n",
    "print(list(test_data['REGION'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ============================================\n",
    "## Work for testing data\n",
    "# data_pack_list = data['TOP_PACK'].unique()\n",
    "\n",
    "# test_data['user_id_num'] = [float(x) for x in range(len(test_data))]\n",
    "\n",
    "# test_data = test_data.drop(labels = ['user_id','TENURE','REGION','TOP_PACK','MRG'],axis=1)\n",
    "# test_data = test_data.drop(labels = ['user_id','MRG','TOP_PACK'],axis=1)\n",
    "# test_data['REGION'] = test_data['REGION'].apply(lambda x: 'DAKAR' if str(x) == str('nan')  else str(x))\n",
    "# test_data = test_data[~test_data.REGION.str.contains('MISSING')]\n",
    "# test_data['TOP_PACK'] = test_data['TOP_PACK'].apply(lambda x: x if x in test_data_pack_list else 'MISSING')\n",
    "# test_data = test_data[~test_data.TOP_PACK.str.contains('MISSING')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_data['TOP_PACK'].unique()),len(data['TOP_PACK'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "#lets check if our data have any null values\n",
    "# print(data.isna().sum())\n",
    "\n",
    "## ============================================\n",
    "## Work for testing data\n",
    "\n",
    "#lets check if our data have any null values\n",
    "print(test_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "\n",
    "data = data.fillna(-99999)\n",
    "# data = data.dropna()\n",
    "\n",
    "## ============================================\n",
    "## Work for testing data\n",
    "\n",
    "test_data = test_data.fillna(-99999)\n",
    "# test_data = test_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_data['TOP_PACK'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data['TOP_PACK'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 36) (400000,)\n"
     ]
    }
   ],
   "source": [
    "## work for training data\n",
    "\n",
    "#Standardizing/scaling the features\n",
    "X = data.drop(['CHURN'],axis=1)\n",
    "X = pd.get_dummies(X)\n",
    "# X_columns = X.columns.values.tolist()\n",
    "scalery = StandardScaler()\n",
    "X = scalery.fit_transform(X)\n",
    "y = data['CHURN']\n",
    "print(X.shape,y.shape)\n",
    "\n",
    "## ============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 36) (100000, 36) 0        af900d87e73b7ff6509d2203df4704a98aa5f2a6\n",
      "1        5335efd940280b82143272275637d1e65d37eadb\n",
      "2        a581f4fa08677c26f83f643248c667e241043086\n",
      "3        64f67177d0775262b8087a9e2e3b8061b6324ae6\n",
      "4        0d6009a4594c4be22449b8d9cc01a0bcea98faea\n",
      "                           ...                   \n",
      "99995    c6bcb3336795a18eb6c0bc7e19078a0704ef4d7e\n",
      "99996    a44b4e44dc70115ed5bf971ebb4193dd536e87f0\n",
      "99997    a2f84faffbc995bd0e2d726fa4ffdb93f11646ed\n",
      "99998    afa76e894df4201fc77eb714de7d1f262299611a\n",
      "99999    c08a2d84b87c1f5d4bb318114f508b77aa8e2663\n",
      "Name: user_id, Length: 100000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Work for testing data\n",
    "\n",
    "#Standardizing/scaling the features\n",
    "X1 = pd.DataFrame.copy(test_data)\n",
    "# X1_ids = pd.DataFrame.copy(test_data['user_id'])\n",
    "# test_data = test_data.drop(labels = ['user_id','MRG','TOP_PACK'],axis=1)\n",
    "X1 = pd.get_dummies(test_data)\n",
    "X_columns = X1.columns.values.tolist()\n",
    "scalery = StandardScaler()\n",
    "X1 = scalery.fit_transform(X1)\n",
    "print(X.shape,X1.shape,X1_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y, test_size=0.2, random_state=0)\n",
    "\n",
    "## ============================================\n",
    "## Work for testing data\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X,y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.879\n",
      "Test set score: 0.878\n"
     ]
    }
   ],
   "source": [
    "## work for training data\n",
    "\n",
    "# clf = RandomForestClassifier(n_jobs=-1,n_estimators=150,max_features=30,min_samples_leaf=2)\n",
    "# clf = LogisticRegression(C=36,class_weight=36)\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "# pred = clf.predict(X_test)\n",
    "print(\"Training set score: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "# print(f'The accurancy score is:{accuracy_score(pred,y_test)*100}%')\n",
    "# print(\"Loss Funtion: {}\".format(log_loss(y_test,pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ============================================\n",
    "## Work for testing data\n",
    "pred = clf.predict(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "\n",
    "# weights = pd.Series(clf.coef_[0],index=X_columns)\n",
    "# weights.sort_values(ascending = False)\n",
    "\n",
    "## ============================================\n",
    "## Work for testing data\n",
    "# To get the weights of all the variables\n",
    "\n",
    "feat_importances = pd.Series(clf.feature_importances_, index=X_columns)\n",
    "feat_importances = feat_importances.nlargest(20)\n",
    "feat_importances.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "## original_x = scalery.inverse_transform(X_test)\n",
    "# original_x = pd.DataFrame(data=original_x,columns=X_columns)\n",
    "# original_x['pred'] = pred\n",
    "# original_x = pd.DataFrame(data = list(zip(original_x['user_id_num'],original_x['pred'])), \n",
    "#                          columns = ['user_id_num', 'pred'])\n",
    "\n",
    "## ============================================\n",
    "## Work for testing data\n",
    "\n",
    "# original_x = scalery.inverse_transform(X_test)\n",
    "original_x = pd.DataFrame(data=X1,columns=X_columns)\n",
    "original_x['pred'] = pred\n",
    "original_x = pd.DataFrame(data = list(zip(original_x['user_id_num'],original_x['pred'])),\n",
    "                          columns = ['user_id_num', 'pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "# real_churn = pd.merge(X1, original_x, on='user_id_num', how='left')\n",
    "# real_churn = pd.DataFrame(data = list(zip(real_churn['user_id'],real_churn['pred']))\n",
    "#                           , columns = ['user_id', 'pred'])\n",
    "# real_churn = real_churn.dropna()\n",
    "# real_churn\n",
    "\n",
    "## ============================================\n",
    "## Work for testing data\n",
    "real_churn = pd.merge(X_copy, original_x, on='user_id_num', how='left')\n",
    "real_churn = pd.DataFrame(data = list(zip(real_churn['user_id'],real_churn['pred']))\n",
    "                          , columns = ['user_id', 'pred'])\n",
    "real_churn = real_churn.dropna()\n",
    "real_churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = scalery.inverse_transform(X1)\n",
    "X1 = pd.DataFrame(data=X1,columns=X_columns)\n",
    "X1['pred'] = pred\n",
    "X1['user_id'] = X1_ids\n",
    "X1 = pd.DataFrame(data = list(zip(X1['pred']))\n",
    "                          , columns = ['CHURN'], index=X1['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHURN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>af900d87e73b7ff6509d2203df4704a98aa5f2a6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5335efd940280b82143272275637d1e65d37eadb</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a581f4fa08677c26f83f643248c667e241043086</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64f67177d0775262b8087a9e2e3b8061b6324ae6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0d6009a4594c4be22449b8d9cc01a0bcea98faea</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          CHURN\n",
       "user_id                                        \n",
       "af900d87e73b7ff6509d2203df4704a98aa5f2a6      1\n",
       "5335efd940280b82143272275637d1e65d37eadb      1\n",
       "a581f4fa08677c26f83f643248c667e241043086      0\n",
       "64f67177d0775262b8087a9e2e3b8061b6324ae6      0\n",
       "0d6009a4594c4be22449b8d9cc01a0bcea98faea      0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data dictionary to understand the meaning of the variable relatively to the business\n",
    "variable_definition = pd.read_csv('VariableDefinitions.csv')\n",
    "variable_definition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
