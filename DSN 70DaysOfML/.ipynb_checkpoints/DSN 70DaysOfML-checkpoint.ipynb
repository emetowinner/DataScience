{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCTION TO MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import quandl,math, datetime\n",
    "from sklearn import preprocessing, svm, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import pickle\n",
    "\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quandl.ApiConfig.api_key = \"mcseWdy4Juq_2h8ux3ss\"\n",
    "df = quandl.get(\"WIKI/GOOGL\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting feature variables from the dataset\n",
    "df = df[['Adj. Open','Adj. High','Adj. Low','Adj. Close','Adj. Volume',]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the percent volatility for the day \n",
    "df['HL_PCT'] = (df['Adj. High']-df['Adj. Close'])/df['Adj. Close']*100\n",
    "## Getting the stoke price percent change for the day\n",
    "df['PCT_Change'] = (df['Adj. Close']-df['Adj. Open'])/df['Adj. Open']*100\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting new fearures that has a defined relationship to help simple linear regression have a better prediction\n",
    "df = df[['Adj. Close','HL_PCT','PCT_Change','Adj. Volume',]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the label\n",
    "forcast_col = 'Adj. Close'\n",
    "df.fillna(-99999, inplace=True)\n",
    "forecast_out = int(math.ceil(0.001*len(df)))\n",
    "df['Label'] = df[forcast_col].shift(-forecast_out)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing selected feature and label to X and y respectively\n",
    "X = np.array(df.drop(['Label'],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling X(feature) to have a common scale point across all the data piont\n",
    "X = preprocessing.scale(X)\n",
    "X_lately = X[-forecast_out:]# grabs data for days ahead depending on the size of the df\n",
    "X = X[:-forecast_out]# grabs data for the last days depending on the size of the df\n",
    "df.dropna(inplace=True)\n",
    "y = np.array(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if data records across X and y are the same\n",
    "print(len(X),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y to training and testing dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our model classifier\n",
    "clf = LinearRegression(n_jobs=-1) # (n_jobs: Number of jobs/threads that can be run at any given time)Tells how many trends you want the training to run under your CPU. (-1: run as many as you can)\n",
    "\n",
    "#Fitting the training set to the classifier\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#save the mode to pickle\n",
    "# with open('linerregression.pickle', 'wb') as f:\n",
    "#     pickle.dump(clf,f)\n",
    "    \n",
    "pickle_in = open('linerregression.pickle','rb')\n",
    "clf = pickle.load(pickle_in)\n",
    "\n",
    "#Test our model with the test set\n",
    "accuracy = clf.score(X_test,y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict pice fo the lately data\n",
    "forecast_set = clf.predict(X_lately)\n",
    "forecast_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Forecast'] = np.nan\n",
    "last_date = df.iloc[-1].name\n",
    "last_unix = last_date.timestamp()\n",
    "one_day = 86400\n",
    "next_unix = last_unix + one_day #next day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in forecast_set:\n",
    "    next_date = datetime.datetime.fromtimestamp(next_unix)\n",
    "    next_unix += one_day\n",
    "    df.loc[next_date] = [np.nan for _ in range(len(df.columns)-1)] + [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Adj. Close'].plot()\n",
    "df['Forecast'].plot(figsize=(30, 10))\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a linear regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs = np.array([1,2,3,4,5,6], dtype=np.float64)\n",
    "# ys = np.array([5,4,6,5,6,7], dtype=np.float64)\n",
    "\n",
    "\n",
    "def create_dataset(hm,variance,step=2,correlation=False):\n",
    "    val = 1 \n",
    "    ys = []\n",
    "    for i in range(hm):\n",
    "        y = val + random.randrange(-variance, variance)\n",
    "        ys.append(y)\n",
    "        if correlation and correlation == 'pos':\n",
    "            val += step\n",
    "        elif correlation and correlation == 'neg':\n",
    "            val -= step\n",
    "    xs = [i for i in range(len(ys))]\n",
    "        \n",
    "    return np.array(xs, dtype=np.float64),np.array(ys, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_fit_slope_and_intercept(xs,ys):\n",
    "    m = ( ((mean(xs) * mean(ys)) - mean(xs*ys) ) / ((mean(xs)**2) - mean(xs**2)) ) \n",
    "    b = (mean(ys)) - (m * mean(xs))\n",
    "    return m,b\n",
    "\n",
    "# Calculating the accuracy of the model wirh R^2 = 1 - [(Squared error of y-regression line) / ( Squared error of the y-mean)].\n",
    "\n",
    "def squared_error(ys_orig,ys_lines):\n",
    "    \n",
    "    return sum((ys_lines-ys_orig)**2)\n",
    "\n",
    "def coef_of_determ(ys_orig,ys_lines):\n",
    "    y_mean_lines = [mean(ys_orig) for y in ys_orig]\n",
    "    squared_error_regr = squared_error(ys_orig,ys_lines)\n",
    "    squared_error_y_mean = squared_error(ys_orig,y_mean_lines)\n",
    "    return 1 - (squared_error_regr/squared_error_y_mean)\n",
    "\n",
    "xs,ys = create_dataset(40,10,2,correlation='pos')\n",
    "\n",
    "m,b = best_fit_slope_and_intercept(xs,ys)\n",
    "print(m,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_line = [(m*x)+b for x in xs]\n",
    "# regression_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xs,ys)\n",
    "plt.plot(xs,regression_line)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting\n",
    "predict_x = 8\n",
    "predict_y = (m*predict_x)+b\n",
    "\n",
    "r_squared = coef_of_determ(ys,regression_line)\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xs,ys)\n",
    "plt.scatter(predict_x,predict_y, color='green')\n",
    "plt.plot(xs,regression_line)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##=================================================\n",
    "# Concepts of KNN Classification\n",
    "\n",
    "df = pd.read_csv(\"breast-cancer-wisconsin.data\")\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(['id'],1,inplace=True)\n",
    "df.drop(['Unnamed: 11'],1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['class'],1))\n",
    "y = np.array(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)\n",
    "accuracy_score = clf.score(X_test,y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_measure = np.array([[2,4,2,3,4,5,1,2,2]])\n",
    "example_measure = example_measure.reshape(len(example_measure),-1)\n",
    "clf.predict(example_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Understanding KNN from scratch\n",
    "\n",
    "from math import sqrt\n",
    "from collections import Counter\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_1 = [1,3]\n",
    "# plot_2 = [2,5]\n",
    "\n",
    "# eucld_distances = []\n",
    "# for p1,p2 in zip(plot_1,plot_2):\n",
    "#     print(p1,\"=======\",p2)\n",
    "#     eucld_distance = (p1-p2)**2\n",
    "#     eucld_distances.append(eucld_distance)\n",
    "# euclidean_distance = sqrt(sum(eucld_distances))\n",
    "# euclidean_distance\n",
    "\n",
    "\n",
    "dataset = {'k':[[1,2],[2,3],[3,1]],'r':[[6,5],[7,7],[8,6]]}\n",
    "new_feature = [5,7]\n",
    "\n",
    "# [[plt.scatter(ii[0],ii[1],s=100,color=i) for ii in dataset[i]] for i in dataset]\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(data,predict,k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn(\"K is set to a value less than total voting group\")\n",
    "    \n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            distances.append([euclidean_distance,group])\n",
    "    \n",
    "    votes = [i[1] for i in sorted(distances)[:k]]\n",
    "    print(Counter(votes).most_common(1))\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    confidence = Counter(votes).most_common(1)[0][1]/k\n",
    "    return vote_result,confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result,confidence = k_nearest_neighbors(dataset,new_feature)\n",
    "print(result,confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"breast-cancer-wisconsin.data\")\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(['id'],1,inplace=True)\n",
    "df.drop(['Unnamed: 11'],1,inplace=True)\n",
    "full_data = df.astype(float).values.tolist()\n",
    "random.shuffle(full_data)\n",
    "full_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "train_set = {2:[],4:[]}\n",
    "test_set = {2:[],4:[]}\n",
    "train_data = full_data[:-int(test_size*len(full_data))]\n",
    "test_data = full_data[-int(test_size*len(full_data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "    train_set[i[-1]].append(i[:-1])\n",
    "\n",
    "for i in test_data:\n",
    "    test_set[i[-1]].append(i[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0 \n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote,confidence = k_nearest_neighbors(train_set,data,k=5)\n",
    "        if group == vote:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>unif_cell_size</th>\n",
       "      <th>unif_cell_shape</th>\n",
       "      <th>marg_adhesion</th>\n",
       "      <th>single_epith_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chrom</th>\n",
       "      <th>norm_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clump_thickness  unif_cell_size  unif_cell_shape  marg_adhesion  \\\n",
       "0                5               1                1              1   \n",
       "1                5               4                4              5   \n",
       "2                3               1                1              1   \n",
       "3                6               8                8              1   \n",
       "4                4               1                1              3   \n",
       "\n",
       "   single_epith_cell_size bare_nuclei  bland_chrom  norm_nucleoli  mitoses  \\\n",
       "0                       2           1            3              1        1   \n",
       "1                       7          10            3              2        1   \n",
       "2                       2           2            3              1        1   \n",
       "3                       3           4            3              7        1   \n",
       "4                       2           1            3              1        1   \n",
       "\n",
       "   class  \n",
       "0      2  \n",
       "1      2  \n",
       "2      2  \n",
       "3      2  \n",
       "4      2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##=================================================\n",
    "# Implementation of Support Vector Machine\n",
    "\n",
    "df = pd.read_csv(\"breast-cancer-wisconsin.data\")\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(['id'],1,inplace=True)\n",
    "df.drop(['Unnamed: 11'],1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['class'],1))\n",
    "y = np.array(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6785714285714286"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)\n",
    "accuracy_score = clf.score(X_test,y_test)\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating An SVM from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportVectorMachine:\n",
    "    def __init__(self,visualization=True):\n",
    "        self.visualization =visualization\n",
    "        self.color = {1:'r',-1:'b'}\n",
    "        if self.visualization:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "    def fit(self,data):\n",
    "        self.data = data\n",
    "        # { ||w||: [w,b] }\n",
    "        opt_dict = {}\n",
    "        \n",
    "        transform = [[1,1],[-1,1],[-1,-1],[1,-1]]\n",
    "        \n",
    "        all_data = []\n",
    "        for yi in self.data:\n",
    "            for featureset in self.data[yi]:\n",
    "                for feature in featureset:\n",
    "                    all_data.append(feature)\n",
    "        \n",
    "        self.max_feature_value = max(all_data)\n",
    "        self.min_feature_value = min(all_data)\n",
    "        all_data = None\n",
    "        \n",
    "        step_size = [self.max_feature_value * 0.1]\n",
    "    \n",
    "    \n",
    "    def predict(self,features)\n",
    "        # sign(x.w+b)\n",
    "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
    "        \n",
    "        return classification\n",
    "\n",
    "\n",
    "data_dict = {-1:np.array([[1,7],[2,8],[3,8]]),\n",
    "             1:np.array([[5,1],[6,-1],[7,3]])}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
