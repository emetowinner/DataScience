{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train.csv')\n",
    "test_data = pd.read_csv('Test.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot\n",
    "print(data['CHURN'].value_counts())\n",
    "sizes = data['CHURN'].value_counts(sort = True)\n",
    "colors = [\"grey\",\"purple\"] \n",
    "rcParams['figure.figsize'] = 5,5\n",
    "labels = ['No','Yes']\n",
    "# Plot\n",
    "plt.pie(sizes, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=270,)\n",
    "plt.title('Percentage of Churn in Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the churn count for MRG\n",
    "sns.countplot(x='MRG', hue='CHURN',data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the churn count for TOP_PACK\n",
    "sns.countplot(x='TOP_PACK', hue='CHURN',data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the churn count for TENURE\n",
    "sns.countplot(x='TENURE', hue='CHURN',data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['REGION'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_country_list = test_data['REGION'].unique()\n",
    "# test_data_pack_list = test_data['TOP_PACK'].unique()\n",
    "\n",
    "## work for training data\n",
    "# data['user_id_num'] = [float(x) for x in range(len(data))]\n",
    "# X_copy = pd.DataFrame.copy(data)\n",
    "# data = data.drop(labels = ['user_id','TENURE','REGION','TOP_PACK','MRG'],axis=1)\n",
    "data = data.drop(labels = ['user_id','MRG','TOP_PACK'],axis=1)\n",
    "# data['REGION'] = data['REGION'].apply(lambda x: x if x in test_data_country_list else 'DAKAR')\n",
    "# data = data[~data.REGION.str.contains('MISSING')]\n",
    "# data['TOP_PACK'] = data['TOP_PACK'].apply(lambda x: x if x in test_data_pack_list else 'MISSING')\n",
    "# data = data[~data.TOP_PACK.str.contains('MISSING')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(data['REGION'].unique()))\n",
    "print(list(test_data['REGION'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ============================================\n",
    "## Work for testing data\n",
    "# data_pack_list = data['TOP_PACK'].unique()\n",
    "\n",
    "# test_data['user_id_num'] = [float(x) for x in range(len(test_data))]\n",
    "\n",
    "# test_data = test_data.drop(labels = ['user_id','TENURE','REGION','TOP_PACK','MRG'],axis=1)\n",
    "# test_data = test_data.drop(labels = ['user_id','MRG','TOP_PACK'],axis=1)\n",
    "# test_data['REGION'] = test_data['REGION'].apply(lambda x: 'DAKAR' if str(x) == str('nan')  else str(x))\n",
    "# test_data = test_data[~test_data.REGION.str.contains('MISSING')]\n",
    "# test_data['TOP_PACK'] = test_data['TOP_PACK'].apply(lambda x: x if x in test_data_pack_list else 'MISSING')\n",
    "# test_data = test_data[~test_data.TOP_PACK.str.contains('MISSING')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_data['TOP_PACK'].unique()),len(data['TOP_PACK'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "#lets check if our data have any null values\n",
    "# print(data.isna().sum())\n",
    "\n",
    "## ============================================\n",
    "## Work for testing data\n",
    "\n",
    "#lets check if our data have any null values\n",
    "print(test_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "\n",
    "data = data.fillna(-99999)\n",
    "# data = data.dropna()\n",
    "\n",
    "## ============================================\n",
    "## Work for testing data\n",
    "\n",
    "test_data = test_data.fillna(-99999)\n",
    "# test_data = test_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_data['TOP_PACK'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data['TOP_PACK'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "\n",
    "#Standardizing/scaling the features\n",
    "X = data.drop(['CHURN'],axis=1)\n",
    "X = pd.get_dummies(X)\n",
    "# X_columns = X.columns.values.tolist()\n",
    "scalery = StandardScaler()\n",
    "X = scalery.fit_transform(X)\n",
    "y = data['CHURN']\n",
    "print(X.shape,y.shape)\n",
    "\n",
    "## ============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Work for testing data\n",
    "\n",
    "#Standardizing/scaling the features\n",
    "X1 = pd.DataFrame.copy(test_data)\n",
    "# X1_ids = pd.DataFrame.copy(test_data['user_id'])\n",
    "# test_data = test_data.drop(labels = ['user_id','MRG','TOP_PACK'],axis=1)\n",
    "X1 = pd.get_dummies(test_data)\n",
    "X_columns = X1.columns.values.tolist()\n",
    "scalery = StandardScaler()\n",
    "X1 = scalery.fit_transform(X1)\n",
    "print(X.shape,X1.shape,X1_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,y, test_size=0.2, random_state=0)\n",
    "\n",
    "## ============================================\n",
    "## Work for testing data\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X,y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "\n",
    "# clf = RandomForestClassifier(n_jobs=-1,n_estimators=150,max_features=30,min_samples_leaf=2)\n",
    "# clf = LogisticRegression(C=36,class_weight=36)\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "# pred = clf.predict(X_test)\n",
    "print(\"Training set score: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "# print(f'The accurancy score is:{accuracy_score(pred,y_test)*100}%')\n",
    "# print(\"Loss Funtion: {}\".format(log_loss(y_test,pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ============================================\n",
    "## Work for testing data\n",
    "pred = clf.predict(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "\n",
    "# weights = pd.Series(clf.coef_[0],index=X_columns)\n",
    "# weights.sort_values(ascending = False)\n",
    "\n",
    "## ============================================\n",
    "## Work for testing data\n",
    "# To get the weights of all the variables\n",
    "\n",
    "feat_importances = pd.Series(clf.feature_importances_, index=X_columns)\n",
    "feat_importances = feat_importances.nlargest(20)\n",
    "feat_importances.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "## original_x = scalery.inverse_transform(X_test)\n",
    "# original_x = pd.DataFrame(data=original_x,columns=X_columns)\n",
    "# original_x['pred'] = pred\n",
    "# original_x = pd.DataFrame(data = list(zip(original_x['user_id_num'],original_x['pred'])), \n",
    "#                          columns = ['user_id_num', 'pred'])\n",
    "\n",
    "## ============================================\n",
    "## Work for testing data\n",
    "\n",
    "# original_x = scalery.inverse_transform(X_test)\n",
    "original_x = pd.DataFrame(data=X1,columns=X_columns)\n",
    "original_x['pred'] = pred\n",
    "original_x = pd.DataFrame(data = list(zip(original_x['user_id_num'],original_x['pred'])),\n",
    "                          columns = ['user_id_num', 'pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## work for training data\n",
    "# real_churn = pd.merge(X1, original_x, on='user_id_num', how='left')\n",
    "# real_churn = pd.DataFrame(data = list(zip(real_churn['user_id'],real_churn['pred']))\n",
    "#                           , columns = ['user_id', 'pred'])\n",
    "# real_churn = real_churn.dropna()\n",
    "# real_churn\n",
    "\n",
    "## ============================================\n",
    "## Work for testing data\n",
    "real_churn = pd.merge(X_copy, original_x, on='user_id_num', how='left')\n",
    "real_churn = pd.DataFrame(data = list(zip(real_churn['user_id'],real_churn['pred']))\n",
    "                          , columns = ['user_id', 'pred'])\n",
    "real_churn = real_churn.dropna()\n",
    "real_churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = scalery.inverse_transform(X1)\n",
    "X1 = pd.DataFrame(data=X1,columns=X_columns)\n",
    "X1['pred'] = pred\n",
    "X1['user_id'] = X1_ids\n",
    "X1 = pd.DataFrame(data = list(zip(X1['pred']))\n",
    "                          , columns = ['CHURN'], index=X1['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data dictionary to understand the meaning of the variable relatively to the business\n",
    "variable_definition = pd.read_csv('VariableDefinitions.csv')\n",
    "variable_definition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
